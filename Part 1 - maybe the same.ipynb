{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть 1: Обработка результатов, поиск возможных совпадений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "ENGLISH_LEVELS = ['элементарный', 'ниже среднего', 'средний', 'выше среднего', 'продвинутый']\n",
    "EDUCATION_LEVELS = ['Среднее', 'Техникум / Колледж', 'Еще студент', 'Незаконченное высшее', 'Высшее', 'Два высших', 'Кандидат']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С декабря 2015, данные содержат поля, позволяющие осуществить первоначальный поиск. Данные за декабрь 2019 не содержат версии final, но остается возможным получить набор данных в необходимом формате, дополнив весию mini датой заполнения и определив \"класс\" заполнителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_dec_final = pd.read_csv('source_csv/2015_dec_final.csv')\n",
    "\n",
    "# Compose dataframe with structure similar to \"final\"\n",
    "df_2019_dec_final = pd.read_csv('source_csv/2019_dec_mini.csv')\n",
    "df_2019_dec_raw = pd.read_csv('source_csv/2019_dec_raw.csv')\n",
    "df_2019_dec_final['Дата.заполнения'] = df_2019_dec_raw['Отметка времени']\n",
    "\n",
    "parsed_dfs = [df_2015_dec_final, df_2019_dec_final] + list(map(pd.read_csv, glob.glob('source_csv/*[6-9]*_final.csv')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, раз уж мы занялись написанием велосипеда, сделаем классы более детальными. Предварительно уберем разницу в названии позиции, вызванную несовпадением регистра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lowercase(value):\n",
    "    if isinstance(value, str):\n",
    "        result = value.replace('engineer', 'Engineer')\n",
    "        result = result.replace('lead', 'Lead')\n",
    "        result = result.replace('analyst', 'Analyst')\n",
    "        result = result.replace('manager', 'Manager')\n",
    "        result = result.replace('coder', 'Coder')\n",
    "\n",
    "        return result\n",
    "\n",
    "def cls_by_position(df):\n",
    "    if df['Язык.программирования'].str != '':\n",
    "        return 'developer'\n",
    "    elif df['Должность'].str.contains('QA'):\n",
    "        return 'QA'\n",
    "    elif df['Должность'].str.contains('esign'):\n",
    "        return 'designer'\n",
    "    elif df['Должность'].isin(['HR', 'Talent Researcher']):\n",
    "        return 'HR'\n",
    "    elif df['Должность'].str.contains('Data'):\n",
    "        return 'data'\n",
    "    elif df['Должность'].isin(['HTML Coder', 'DevOps', 'Sysadmin', 'DBA', 'Security Specialist', 'Research Engineer']):\n",
    "        return 'tech'\n",
    "    elif df['Должность'].isin(['Senior Project Manager / Program Manager', 'Director of Engineering / Program Director',\n",
    "                                  'Business analyst', 'Project manager', 'Team lead', 'Scrum Master', 'Product Manager', 'Sales manager',\n",
    "                                  'Technical writer']):\n",
    "        return 'PM'\n",
    "    else:\n",
    "        return 'other'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем значения для даты заполнения, опыта, возраста, уровня английского и образования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Columns: Index(['N', 'Должность', 'Язык.программирования', 'Специализация',\n       'Общий.опыт.работы', 'Опыт.работы.на.текущем.месте', 'Зарплата.в.месяц',\n       'Изменение.зарплаты.за.12.месяцев', 'Город', 'Размер.компании',\n       'Тип.компании', 'Пол', 'Возраст', 'Образование', 'Университет',\n       'Еще.студент', 'Уровень.английского', 'Предметная.область',\n       'Дата.заполнения', 'User.Agent', 'exp', 'current_job_exp', 'loc',\n       'salary', 'Валюта', 'cls', 'timestamp', 'english_level',\n       'education_level', 'age'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "\n",
    "for df in parsed_dfs:\n",
    "  df['Должность'] = df['Должность'].apply(fix_lowercase)\n",
    "  df['cls'] = cls_by_position(df)\n",
    "  df['timestamp'] = pd.to_datetime(df['Дата.заполнения'], utc=True)\n",
    "  df['english_level'] = df['Уровень.английского'].apply(lambda x: ENGLISH_LEVELS.index(x))\n",
    "  df['education_level'] = df['Образование'].apply(lambda x: EDUCATION_LEVELS.index(x))\n",
    "\n",
    "  df['current_job_exp'] = df['current_job_exp'].astype(float)\n",
    "  df['exp'] = df['exp'].astype(float)\n",
    "  df['salary'] = df['Зарплата.в.месяц'].astype(float)\n",
    "  \n",
    "  df['age'] = df['Возраст'].astype(float)\n",
    "\n",
    "print(f'Columns: {df.columns}')\n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После заполнения, уберем неиспользующиеся или продублированные столбцы. Отсортируем результаты по дате заполнения. Еще, взгляд на названия столбцов не в английской кодировке вызывает приступы боли, поэтому переиенуем-переведем оставшиеся столбцы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP_COLUMNS = set(['User.Agent', 'Дата.заполнения', 'Зарплата.в.месяц', 'Уровень.английского', 'Образование',\n",
    "                   'Возраст', 'Общий.опыт.работы', 'Опыт.работы.на.текущем.месте', 'Еще.студент'])\n",
    "\n",
    "for df in parsed_dfs:\n",
    "    columns_to_drop = CLEANUP_COLUMNS.intersection(df.columns)\n",
    "    df.drop(columns_to_drop, inplace=True, axis=1)\n",
    "    df.rename(columns={\n",
    "        'Должность': 'position',\n",
    "        'Язык.программирования': 'programming_language',\n",
    "        'Специализация': 'speciality',\n",
    "        'Изменение.зарплаты.за.12.месяцев': 'salary_delta_1y',\n",
    "        'Город': 'city',\n",
    "        'Размер.компании': 'company_size',\n",
    "        'Тип.компании': 'company_type',\n",
    "        'Пол': 'gender',\n",
    "        'Университет': 'university',\n",
    "        'Предметная.область': 'subject_area',\n",
    "        'Валюта': 'currency'\n",
    "    }, inplace=True)\n",
    "\n",
    "parsed_dfs.sort(key=lambda x: x['timestamp'].iloc[0])\n",
    "\n",
    "source_df = pd.concat(parsed_dfs)\n",
    "source_df.to_csv('result_csv/concatenated_source.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные и работу с ними реально перенести в базу, но читаемость и поддериваемость у кода на Python будут выше. Поэтому, разобьем объединение данных на несколько этапов и выполним их для результатов каждого опроса в отдельности.\n",
    "\n",
    "<ul>\n",
    "    <li> Объединяем набор данных по полям \"Университет\" и \"Пол\", т.к. эти поля будут изменятся для одной карьеры между опросами c наименьшей вероятностью. </li>\n",
    "    <li> Убираем заведомо неверные записи, чтобы уменьшить результат выборки </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предполагается, что DataFrame с результатами нового опроса присоединяется к начальным данным с суффиксом. Сделаем несколько предположений (пусть несколько натянутых и условных) для объединенного набора данных, помня, что имеем дело с реальным человеком.\n",
    "Добавим несколько методов для валидации строки, содержащей данные из 2х опросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Уровень образования не ухудшается. Во всяком случае, никто не признается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def education_level_not_dropped(df):\n",
    "    return df['education_level' + JOINED_SUFFIX] >= df['education_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Данные не относятся к одному и тому же опросу и соединены в правильной последовательности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_different_surveys(df):\n",
    "    return np.where(df['time_delta'] > pd.Timedelta(90, 'D'), True, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Уровень английского не ухудшается с течением времени.  Специфика отрасли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_level_check(df):\n",
    "    return df['english_level' + JOINED_SUFFIX] >= df['english_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Возраст изменяется с течением времени. Допустим погрешность в 1 год."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_check(df):\n",
    "    age_diff = df['age' + JOINED_SUFFIX] - df['age']\n",
    "    survey_age_diff = (age_diff - df['years_delta'])\n",
    "\n",
    "    return np.where((survey_age_diff <= 1) & (survey_age_diff >= 0), True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Опыт работы на позиции обнуляется при смене компании. Будем считать, что компания изменяется, когда изменяется ее тип."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_place_experience_check(df):\n",
    "    company_type_same = df['company_type'] != df['company_type' + JOINED_SUFFIX]\n",
    "    experience_diff = df['current_job_exp' + JOINED_SUFFIX] - df['current_job_exp']\n",
    "\n",
    "    return company_type_same | df['years_delta'] > experience_diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Общий опыт работы изменяется с течением времени. Допустим погрешность в 1 год."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_experience_check(df):\n",
    "    experience_diff = df['exp' + JOINED_SUFFIX] - df['exp']\n",
    "    survey_experience_diff = df['years_delta'] - experience_diff\n",
    "\n",
    "    return (survey_experience_diff <= 1) & (survey_experience_diff >= 0) & (experience_diff >= 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Если опросы проведены с интервалом в 1 год, разница в з/п соответствует указанному изменению з/п за 12 месяцев. Допустим временную погрешность в ~2 месяца"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спойлер:\n",
    "\n",
    "Заметно, что датасеты, имеющие разницу в ~год, и отфильтрованные с помощью этого метода, имеют меньше общих строк. Причем, возможность произвести эту проверку уменьшает размер результирующей выборки в ~4 раза по сравнению с соседними и более чем в 2 раза - по сравнению с исходным датасетом. Это может значить, что неверен либо способ проверки, либо более половины тестового набора заполняется с ошибками. Есть над чем подумать, а пока вызов закомментирован."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_delta_check(df):\n",
    "    passed_not_year = (df['years_delta'] - 1).abs() > 0.16 # 2 months = ~0.16 of a year\n",
    "    salary_diff = df['salary' + JOINED_SUFFIX] - df['salary']\n",
    "\n",
    "    return passed_not_year | (salary_diff == df['salary_delta_1y' + JOINED_SUFFIX])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Уровень программиста не падает при условии постоянного стека. Деградация на легаси? Не, не слышал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROGRAMMER_LEVELS = ['Junior Software Engineer', 'Software Engineer', 'Senior Software Engineer']\n",
    "PROGRAMMER_TOP_LEVELS= ['Senior Software Engineer', 'Technical Lead', 'System Architect']\n",
    "\n",
    "def dev_level_not_dropped(df):\n",
    "    different_languages = df['programming_language'] != df['programming_language' + JOINED_SUFFIX]\n",
    "    source_level = df['position'].apply(lambda x: PROGRAMMER_LEVELS.index(x) if x in PROGRAMMER_LEVELS else 0)\n",
    "    joined_level = df['position' + JOINED_SUFFIX].apply(lambda x: PROGRAMMER_LEVELS.index(x) if x in PROGRAMMER_LEVELS else 0)\n",
    "    joined_top_level = df['position' + JOINED_SUFFIX].isin(PROGRAMMER_TOP_LEVELS)\n",
    "\n",
    "    return different_languages | joined_top_level | (source_level <= joined_level)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Уровень QA не падает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_LEVELS = ['Junior QA engineer', 'QA engineer', 'Senior QA engineer', 'QA Tech Lead']\n",
    "\n",
    "def qa_level_not_dropped(df):\n",
    "    not_qa = result['cls'] != 'QA'\n",
    "    source_level = df['position'].apply(lambda x: QA_LEVELS.index(x) if x in QA_LEVELS else 0)\n",
    "    joined_level = df['position' + JOINED_SUFFIX].apply(lambda x: QA_LEVELS.index(x) if x in QA_LEVELS else 0)\n",
    "\n",
    "    return not_qa | (source_level <= joined_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Спорная проверка: программисты и PM не переквалифицируются в QA и HR. Дайте знать, если известны опровергающие случаи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_check(df):\n",
    "    return df['cls'].isin(['developer', 'PM']) & ~df['cls' + JOINED_SUFFIX].isin(['QA', 'HR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Processing DataFrame 1 of 9\nMerging with candidate DataFrame 1 of 8\nIncoming DataFrame size: 7340\nLines in merge result: 4236361\nLines after filtering: 14295\nMerging with candidate DataFrame 2 of 8\nIncoming DataFrame size: 8868\nLines in merge result: 5185086\nLines after filtering: 20592\nMerging with candidate DataFrame 3 of 8\nIncoming DataFrame size: 8704\nLines in merge result: 5015266\nLines after filtering: 17072\nMerging with candidate DataFrame 4 of 8\nIncoming DataFrame size: 8355\nLines in merge result: 4880894\nLines after filtering: 14538\nMerging with candidate DataFrame 5 of 8\nIncoming DataFrame size: 9610\nLines in merge result: 5497033\nLines after filtering: 13512\nMerging with candidate DataFrame 6 of 8\nIncoming DataFrame size: 10379\nLines in merge result: 5757114\nLines after filtering: 13813\nMerging with candidate DataFrame 7 of 8\nIncoming DataFrame size: 11439\nLines in merge result: 6196657\nLines after filtering: 12286\nMerging with candidate DataFrame 8 of 8\nIncoming DataFrame size: 10186\nLines in merge result: 4793150\nLines after filtering: 9016\nProcessing DataFrame 2 of 9\nMerging with candidate DataFrame 1 of 7\nIncoming DataFrame size: 8868\nLines in merge result: 5214535\nLines after filtering: 21092\nMerging with candidate DataFrame 2 of 7\nIncoming DataFrame size: 8704\nLines in merge result: 5049427\nLines after filtering: 19004\nMerging with candidate DataFrame 3 of 7\nIncoming DataFrame size: 8355\nLines in merge result: 4915183\nLines after filtering: 16211\nMerging with candidate DataFrame 4 of 7\nIncoming DataFrame size: 9610\nLines in merge result: 5537380\nLines after filtering: 14559\nMerging with candidate DataFrame 5 of 7\nIncoming DataFrame size: 10379\nLines in merge result: 5802477\nLines after filtering: 14857\nMerging with candidate DataFrame 6 of 7\nIncoming DataFrame size: 11439\nLines in merge result: 6250643\nLines after filtering: 14506\nMerging with candidate DataFrame 7 of 7\nIncoming DataFrame size: 10186\nLines in merge result: 4842622\nLines after filtering: 9622\nProcessing DataFrame 3 of 9\nMerging with candidate DataFrame 1 of 6\nIncoming DataFrame size: 8704\nLines in merge result: 6189598\nLines after filtering: 20379\nMerging with candidate DataFrame 2 of 6\nIncoming DataFrame size: 8355\nLines in merge result: 6028005\nLines after filtering: 22149\nMerging with candidate DataFrame 3 of 6\nIncoming DataFrame size: 9610\nLines in merge result: 6794457\nLines after filtering: 21365\nMerging with candidate DataFrame 4 of 6\nIncoming DataFrame size: 10379\nLines in merge result: 7120577\nLines after filtering: 21078\nMerging with candidate DataFrame 5 of 6\nIncoming DataFrame size: 11439\nLines in merge result: 7674153\nLines after filtering: 18995\nMerging with candidate DataFrame 6 of 6\nIncoming DataFrame size: 10186\nLines in merge result: 5961355\nLines after filtering: 14289\nProcessing DataFrame 4 of 9\nMerging with candidate DataFrame 1 of 5\nIncoming DataFrame size: 8355\nLines in merge result: 5851573\nLines after filtering: 22593\nMerging with candidate DataFrame 2 of 5\nIncoming DataFrame size: 9610\nLines in merge result: 6593891\nLines after filtering: 23969\nMerging with candidate DataFrame 3 of 5\nIncoming DataFrame size: 10379\nLines in merge result: 6914839\nLines after filtering: 22169\nMerging with candidate DataFrame 4 of 5\nIncoming DataFrame size: 11439\nLines in merge result: 7460233\nLines after filtering: 22151\nMerging with candidate DataFrame 5 of 5\nIncoming DataFrame size: 10186\nLines in merge result: 5806122\nLines after filtering: 14989\nProcessing DataFrame 5 of 9\nMerging with candidate DataFrame 1 of 4\nIncoming DataFrame size: 9610\nLines in merge result: 6443591\nLines after filtering: 22250\nMerging with candidate DataFrame 2 of 4\nIncoming DataFrame size: 10379\nLines in merge result: 6762562\nLines after filtering: 25531\nMerging with candidate DataFrame 3 of 4\nIncoming DataFrame size: 11439\nLines in merge result: 7301483\nLines after filtering: 23059\nMerging with candidate DataFrame 4 of 4\nIncoming DataFrame size: 10186\nLines in merge result: 5638390\nLines after filtering: 16188\nProcessing DataFrame 6 of 9\nMerging with candidate DataFrame 1 of 3\nIncoming DataFrame size: 10379\nLines in merge result: 7629139\nLines after filtering: 26261\nMerging with candidate DataFrame 2 of 3\nIncoming DataFrame size: 11439\nLines in merge result: 8245099\nLines after filtering: 28989\nMerging with candidate DataFrame 3 of 3\nIncoming DataFrame size: 10186\nLines in merge result: 6362577\nLines after filtering: 19083\nProcessing DataFrame 7 of 9\nMerging with candidate DataFrame 1 of 2\nIncoming DataFrame size: 11439\nLines in merge result: 8672926\nLines after filtering: 24677\nMerging with candidate DataFrame 2 of 2\nIncoming DataFrame size: 10186\nLines in merge result: 6713989\nLines after filtering: 22245\nProcessing DataFrame 8 of 9\nMerging with candidate DataFrame 1 of 1\nIncoming DataFrame size: 10186\nLines in merge result: 7282914\nLines after filtering: 23875\nProcessing DataFrame 9 of 9\nMerged 36 pairs of DataFrames\n"
    }
   ],
   "source": [
    "# First, merge DataFrames by pairs\n",
    "JOINED_SUFFIX = '_joined'\n",
    "\n",
    "result_dfs = []\n",
    "candidate_dfs = parsed_dfs.copy()\n",
    "for parsed_index, parsed_df in enumerate(parsed_dfs):\n",
    "    candidate_dfs.remove(parsed_df)\n",
    "    print(f'Обработка DataFrame {parsed_index + 1} из {len(parsed_dfs)}')\n",
    "\n",
    "    for candidate_index, candidate_df in enumerate(candidate_dfs):\n",
    "        print(f'Обработка входящего DataFrame {candidate_index + 1} из {len(candidate_dfs)}')\n",
    "        result = parsed_df.merge(candidate_df, on=['university', 'gender'], suffixes=('', JOINED_SUFFIX))\n",
    "        result['time_delta'] = result['timestamp' + JOINED_SUFFIX] - result['timestamp']\n",
    "        result['years_delta'] = result['time_delta']/np.timedelta64(1, 'Y')\n",
    "        print(f'Размер входящего датасета: {len(candidate_df)}')\n",
    "        print(f'Результатов после left join: {len(result)}')\n",
    "        \n",
    "        # Apply validations\n",
    "        result = result[\n",
    "            # salary_delta_check(result) &\n",
    "            # are_different_surveys(result) &\n",
    "            english_level_check(result) &\n",
    "            age_check(result) &\n",
    "            total_experience_check(result) &\n",
    "            education_level_not_dropped(result) &\n",
    "            current_place_experience_check(result) &\n",
    "            dev_level_not_dropped(result) &\n",
    "            qa_level_not_dropped(result) &\n",
    "            cls_check(result)\n",
    "        ]\n",
    "\n",
    "        print(f'Результатов после валидации: {len(result)}')\n",
    "        result_dfs.append(result)\n",
    "\n",
    "print(f'Всего {len(result_dfs)} пар датасетов.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим веса для отфильтрованных записей. Вес - число совпадений в столбцах. Значения столбца могут измениться для одного и того же анонимуса и разных опросов, но тем не менее, их совпадение - хороший знак. А ты веришь в знаки при анализе данных, %username%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 36/36 [02:27<00:00,  4.09s/it]\n"
    }
   ],
   "source": [
    "\n",
    "# Number of other coincidences between dataframes\n",
    "WEIGHT_COLUMNS = ['programming_language', 'position', 'speciality', 'city',  'company_size',\n",
    "                  'company_type', 'subject_area']\n",
    "\n",
    "def weights(row):\n",
    "    result = 0\n",
    "    for original_column in WEIGHT_COLUMNS:\n",
    "        if row[original_column] == row[original_column + JOINED_SUFFIX]:\n",
    "            result += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "for df in tqdm(result_dfs):\n",
    "    df[\"weight\"] = df.apply(weights, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый результат можно уникально идентифицировать по комбинации значения N и timestamp. Вынесем соcтавные первичные ключи в отдельный датасет и сохранимся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Сохраняемся..\nСохранен\n"
    }
   ],
   "source": [
    "print(\"Сохранение результатов...\")\n",
    "\n",
    "full_df = pd.concat(result_dfs)\n",
    "full_df.to_csv('result_csv/full.csv')\n",
    "\n",
    "join_df = full_df[['N', 'timestamp', 'N' + JOINED_SUFFIX, 'timestamp' + JOINED_SUFFIX, 'weight']]\n",
    "join_df.to_csv('result_csv/join.csv')\n",
    "\n",
    "\n",
    "print(\"Завершено.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}